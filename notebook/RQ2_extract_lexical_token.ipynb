{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04485d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os\n",
    "token = os.getenv('GITHUB_TOKEN', '')\n",
    "import lex, lexxml, lexpy, lexjs\n",
    "lexpy = lexpy.gen(lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5d84c9-1724-44b4-8949-d2c5c828f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_string = '19000_20000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b567fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../660_data/py_project_commit_'+saving_string+'.pickle',\"rb\") as f:\n",
    "    project_output_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "911dd5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2682.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# remove alias\n",
    "\n",
    "def remove_alias(project_output_dict):\n",
    "    with tqdm(total=len(list(project_output_dict.keys()))) as pbar:\n",
    "        for project_url, test_project_commit in project_output_dict.items():\n",
    "            remove_alias_dict = {}\n",
    "            for commit, value in test_project_commit.items():\n",
    "                [author_name, author_email] = project_output_dict[project_url][commit]['author'].split('<')\n",
    "                # Get Author name, email and email prefix\n",
    "                project_output_dict[project_url][commit]['author_name'] = author_name\n",
    "                project_output_dict[project_url][commit]['author_email'] = author_email\n",
    "                project_output_dict[project_url][commit]['author_prefix'] = author_email.split('@')[0]\n",
    "\n",
    "                if author_email in remove_alias_dict:\n",
    "                    remove_alias_dict[author_email].append(author_name)\n",
    "                else:\n",
    "                    remove_alias_dict[author_email] = []\n",
    "\n",
    "            # Find if there is any duplicates in merge author name and email prefix\n",
    "            for commit, value in test_project_commit.items():\n",
    "                [author_name, author_email] = project_output_dict[project_url][commit]['author'].split('<')\n",
    "                author_prefix = author_email.split('@')[0]\n",
    "                if author_name in remove_alias_dict[author_email] or author_prefix in in remove_alias_dict[author_email]:\n",
    "                    project_output_dict[project_url][commit]['author_name'] = remove_alias_dict[author_email][0]\n",
    "\n",
    "            # Find if there is any duplicates in author names but with different email\n",
    "            remove_alias_dict = {}\n",
    "            for commit, value in test_project_commit.items():\n",
    "                [author_name, author_email] = project_output_dict[project_url][commit]['author'].split('<')\n",
    "                if author_name in remove_alias_dict:\n",
    "                    remove_alias_dict[author_name].append(author_email)\n",
    "                else:\n",
    "                    remove_alias_dict[author_name] = []\n",
    "\n",
    "            # Merge alias with the same author_email\n",
    "            for commit, value in test_project_commit.items():\n",
    "                [author_name, author_email] = project_output_dict[project_url][commit]['author'].split('<')\n",
    "                if project_output_dict[project_url][commit]['author_name'] in remove_alias_dict[author_name]:\n",
    "                project_output_dict[project_url][commit]['author_email'] = remove_alias_dict[author_name][0]\n",
    "        pbar.update(1)\n",
    "    return project_output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5c951f-003b-4b99-8ff1-af7a8f7d6ea5",
   "metadata": {},
   "source": [
    "Extract lexical tokens from github.diff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534e386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_py_token(input_string):\n",
    "    '''\n",
    "    param:\n",
    "        input_string: python source codes\n",
    "    return:\n",
    "        \n",
    "    '''\n",
    "    lexer = lex.Lexer(lexpy, input_string)\n",
    "    token_list = []\n",
    "    while (True):\n",
    "        t = lexer.get_token();\n",
    "        if (t is None): \n",
    "            break;\n",
    "        token_list.append(lexer.repr_token(t))\n",
    "    return token_list\n",
    "\n",
    "def CountFrequency(my_list):\n",
    " \n",
    "    # Creating an empty dictionary\n",
    "    freq = {}\n",
    "    for item in my_list:\n",
    "        if (item in freq):\n",
    "            freq[item] += 1\n",
    "        else:\n",
    "            freq[item] = 1\n",
    "    return freq\n",
    "        \n",
    "\n",
    "def filter_multi_author_py_files(data_dict):\n",
    "    files_count = {}\n",
    "    for author, value in data_dict.items():\n",
    "        for file, tokens in value.items():\n",
    "            if file in files_count:\n",
    "                files_count[file] += 1\n",
    "            else:\n",
    "                files_count[file] = 1\n",
    "    result_files = []\n",
    "    for key, value in files_count.items():\n",
    "        if value > 1:\n",
    "            result_files.append(key)\n",
    "    return result_files\n",
    "\n",
    "\n",
    "def generate_token_ACE_list(data_dict, project_url, collabrate_files):\n",
    "    df_record = []\n",
    "    for author, value in data_dict.items():\n",
    "        for collabrate_file in collabrate_files:\n",
    "            if collabrate_file in value:\n",
    "                for token, count in value[collabrate_file].items():\n",
    "                    df_record.append([author, collabrate_file, token, count])\n",
    "\n",
    "    df = pd.DataFrame.from_records(df_record, columns=['author_email', 'file_name', 'token', 'count'])\n",
    "    token_ACE = []\n",
    "    for file in df['file_name'].unique():\n",
    "        temp = df[df['file_name'] == file].groupby('token').agg({'author_email':'nunique'})\n",
    "        tokens = temp[temp['author_email'] > 1].index.tolist()\n",
    "        for token in tokens:\n",
    "            temp_numpy = df[df['token'] == token]['count'].to_numpy()\n",
    "            total = np.sum(temp_numpy)\n",
    "            temp_probability = temp_numpy/total\n",
    "            cross_entropy = -np.sum(temp_probability * np.log(temp_probability))\n",
    "            token_ACE.append([project_url, token, cross_entropy,file, len(temp_numpy)]) # token, cross_entropy, file, num_author\n",
    "    return token_ACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f77983ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1000/1000 [16:05:13<00:00, 57.91s/it]\n"
     ]
    }
   ],
   "source": [
    "final_result = []\n",
    " \n",
    "with tqdm(total=1000) as pbar:\n",
    "    for project_url in list(project_output_dict.keys())[:1000]:  \n",
    "        test_project_commit  = project_output_dict[project_url]\n",
    "        pbar.update(1)\n",
    "        data_dict = {}\n",
    "        url_params = '/'.join(project_url.split('/')[-2:])\n",
    "        for commit, value in test_project_commit.items():\n",
    "        #     if len(list(value.keys())) != 0:\n",
    "            data_dict[value['author_email']] = {}\n",
    "            query_url = f\"https://api.github.com/repos/\"+url_params+\"/commits/\"+commit\n",
    "            params = {\n",
    "                \"state\": \"open\",\n",
    "            }\n",
    "            headers = {'Authorization': f'token {token}', 'Accept': 'application/vnd.github.diff',}\n",
    "            r = requests.get(query_url, headers=headers, params=params)\n",
    "            diff_list = list(r.iter_lines())\n",
    "            python_file_start = False\n",
    "            token_list = []\n",
    "            for row in diff_list:\n",
    "                row = row.decode('utf-8', 'ignore')\n",
    "        #         if row[:3] == '---' or row[:3] == '+++':\n",
    "                if row[:3] == '+++':\n",
    "\n",
    "                    if row[4:][-2:] == 'py':\n",
    "                        python_file_start = True\n",
    "                        file = row[4:]\n",
    "                        token_list = []\n",
    "                    else:\n",
    "                        if len(token_list) > 0:\n",
    "                            data_dict[value['author_email']][file] = CountFrequency(token_list)\n",
    "                        python_file_start = False\n",
    "                    continue\n",
    "    #             if python_file_start and (row[0] == '-' or row[0] == '+'):\n",
    "                if python_file_start and len(row) > 0 and row[0] == '+':\n",
    "                    input_string = row[1:].strip(' ')\n",
    "                    token_list.extend(print_py_token(input_string))\n",
    "\n",
    "        collabrate_files = filter_multi_author_py_files(data_dict)\n",
    "        if len(collabrate_files) == 0:\n",
    "            continue\n",
    "        token_ACE = generate_token_ACE_list(data_dict, project_url, collabrate_files)\n",
    "        final_result.extend(token_ACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5335606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_url</th>\n",
       "      <th>token</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>file</th>\n",
       "      <th>num_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/thisisaaronland/go-iiif</td>\n",
       "      <td>Token(text=\"'%s.jpg'\", type=STRING, flags=NEXT...</td>\n",
       "      <td>0.636514</td>\n",
       "      <td>b/vendor/src/github.com/fogleman/primitive/bot...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/thisisaaronland/go-iiif</td>\n",
       "      <td>Token(text=\"'%s.png'\", type=STRING, flags=NEXT...</td>\n",
       "      <td>0.636514</td>\n",
       "      <td>b/vendor/src/github.com/fogleman/primitive/bot...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/thisisaaronland/go-iiif</td>\n",
       "      <td>Token(text=\"''\", type=STRING, flags=NEXT_NO_OP...</td>\n",
       "      <td>0.673012</td>\n",
       "      <td>b/vendor/src/github.com/fogleman/primitive/bot...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/thisisaaronland/go-iiif</td>\n",
       "      <td>Token(text=\"'id'\", type=STRING, flags=NEXT_NO_...</td>\n",
       "      <td>0.562335</td>\n",
       "      <td>b/vendor/src/github.com/fogleman/primitive/bot...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/thisisaaronland/go-iiif</td>\n",
       "      <td>Token(text=' ', type=WHITESPACE, flags=IGNORE,...</td>\n",
       "      <td>0.683629</td>\n",
       "      <td>b/vendor/src/github.com/fogleman/primitive/bot...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20910</th>\n",
       "      <td>https://github.com/clemsonacm/hackpack</td>\n",
       "      <td>Token(text='type', type=IDENTIFIER, flags=NEXT...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>b/hackpack/util/convertcppman.py</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20911</th>\n",
       "      <td>https://github.com/clemsonacm/hackpack</td>\n",
       "      <td>Token(text='with', type=KEYWORD, flags=NONE, s...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>b/hackpack/util/convertcppman.py</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20912</th>\n",
       "      <td>https://github.com/clemsonacm/hackpack</td>\n",
       "      <td>Token(text='write', type=IDENTIFIER, flags=MEM...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>b/hackpack/util/convertcppman.py</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20913</th>\n",
       "      <td>https://github.com/clemsonacm/hackpack</td>\n",
       "      <td>Token(text='yield', type=KEYWORD, flags=NONE, ...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>b/hackpack/util/convertcppman.py</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20914</th>\n",
       "      <td>https://github.com/clemsonacm/hackpack</td>\n",
       "      <td>Token(text='|', type=OPERATOR, flags=NONE, sta...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>b/hackpack/util/convertcppman.py</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20915 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      project_url  \\\n",
       "0      https://github.com/thisisaaronland/go-iiif   \n",
       "1      https://github.com/thisisaaronland/go-iiif   \n",
       "2      https://github.com/thisisaaronland/go-iiif   \n",
       "3      https://github.com/thisisaaronland/go-iiif   \n",
       "4      https://github.com/thisisaaronland/go-iiif   \n",
       "...                                           ...   \n",
       "20910      https://github.com/clemsonacm/hackpack   \n",
       "20911      https://github.com/clemsonacm/hackpack   \n",
       "20912      https://github.com/clemsonacm/hackpack   \n",
       "20913      https://github.com/clemsonacm/hackpack   \n",
       "20914      https://github.com/clemsonacm/hackpack   \n",
       "\n",
       "                                                   token  cross_entropy  \\\n",
       "0      Token(text=\"'%s.jpg'\", type=STRING, flags=NEXT...       0.636514   \n",
       "1      Token(text=\"'%s.png'\", type=STRING, flags=NEXT...       0.636514   \n",
       "2      Token(text=\"''\", type=STRING, flags=NEXT_NO_OP...       0.673012   \n",
       "3      Token(text=\"'id'\", type=STRING, flags=NEXT_NO_...       0.562335   \n",
       "4      Token(text=' ', type=WHITESPACE, flags=IGNORE,...       0.683629   \n",
       "...                                                  ...            ...   \n",
       "20910  Token(text='type', type=IDENTIFIER, flags=NEXT...       0.693147   \n",
       "20911  Token(text='with', type=KEYWORD, flags=NONE, s...       0.693147   \n",
       "20912  Token(text='write', type=IDENTIFIER, flags=MEM...       0.693147   \n",
       "20913  Token(text='yield', type=KEYWORD, flags=NONE, ...       0.693147   \n",
       "20914  Token(text='|', type=OPERATOR, flags=NONE, sta...       0.693147   \n",
       "\n",
       "                                                    file  num_author  \n",
       "0      b/vendor/src/github.com/fogleman/primitive/bot...           2  \n",
       "1      b/vendor/src/github.com/fogleman/primitive/bot...           2  \n",
       "2      b/vendor/src/github.com/fogleman/primitive/bot...           2  \n",
       "3      b/vendor/src/github.com/fogleman/primitive/bot...           2  \n",
       "4      b/vendor/src/github.com/fogleman/primitive/bot...           2  \n",
       "...                                                  ...         ...  \n",
       "20910                   b/hackpack/util/convertcppman.py           2  \n",
       "20911                   b/hackpack/util/convertcppman.py           2  \n",
       "20912                   b/hackpack/util/convertcppman.py           2  \n",
       "20913                   b/hackpack/util/convertcppman.py           2  \n",
       "20914                   b/hackpack/util/convertcppman.py           2  \n",
       "\n",
       "[20915 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(final_result, columns=['project_url','token', 'cross_entropy', 'file', 'num_author'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b65afac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('ACE_first_'+saving_string+'.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
